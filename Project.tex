\documentclass{article}
\usepackage{times}
\usepackage{url}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{graphics}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{amsmath,amsfonts}
\usepackage{lmodern}
\usepackage{listings}
\usepackage{float}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{enumerate}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\newcommand{\mytilde}{\raise.17ex\hbox{$\scriptstyle\mathtt{\sim}$}}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

\title{The McEliece Code-based Public Key Cryptosystem}

\author{Palmer Adonis Lao\\
 laopa@clarkson.edu\\
% For a paper whose authors are all at the same institution, 
% omit the following lines up until the closing ''}''.
% Additional authors and addresses can be added with ''\and'', 
% just like the second author.
\and
Sean P. Lyons\\
lyonssp@clarkson.edu\\}
\thispagestyle{empty}

\begin{document}
\maketitle


\begin{abstract}
As the world draws closer to the era of quantum computing, there is a fear on the minds of cryptographers and those who depend on the cryptographic technologies used in everyday life. Shor's algorithm, once it is useful in practice, has the ability to break systems like RSA and ElGamal, that protect the world's most sensitive data. This paper presents a system developed by Robert McEliece.  This code-based, public key cryptosystem, known as the McEliece cryptosystem, is one of few existing classic cryptosystems that cannot be broken by Shor's algorithm or other extensions of the Hidden Subgroup Problem.  In our paper we will present some necessary exposition on linear codes, explanation of the hardness of decoding a linear code, and the details of the cryptosystem itself.   
\end{abstract}

\newpage

\section{Error-correcting Codes}
\paragraph{} Common data transmissions are ridden with potential for error.  These errors can take shape as a result of all kinds of physical imperfections in the channel over which data is being sent.  Regardless, we don't seem to have any issues sending text messages over immense distances or receiving those messages when impurities effect them.  This is a result of \textbf{error-correcting codes}.  A common method of providing some facility to correct transmission errors is redundancy.  As an example, suppose I want to send a single bit, 0.  Now suppose as a way of correcting any error, I simply append two extra copies of the string to itself to get the message 000.  Any corruption that occurs when I send this bit string across a channel will reflect on the string as flipped bits.  Because the original message has been tripled, it is clear that 100 is not a valid bit-string, because there is no string that you can triple-duplicate to get 100.  By the same token, 110 is also an invalid string.  If the receiver sees behavior like this, they know there was an error in transmission.  It is clear from the example that our error-correcting scheme can only \textbf{detect} up to 2 errors.  That is, if all three bits get flipped due to transmission error, the receiver would be unaware because 111 is a valid bit string.  \\
\paragraph{} Now let's turn to the issue of \textbf{correcting} the error.  If a single bit is flipped, rendering the bit string 100 on the receiving end, can the error be corrected?  The answer is yes.  If we assume that there has only been one transmission error, then we know that the original string only consisted of the bits that are the majority bits in the corrupted string.  However, there is an issue here on the receiving end.  How does the receiver know that the original string was not 111 and the received string does not reflect 2 transmission errors?  The error-correcting scheme described is said to only \textbf{correct} 1 error, because once there is a chance that a second error may have occured, there is no way to recover the original message. 
\paragraph{} A couple of the properties hidden in the example above actually generalize to some important properties of linear codes of arbitrary length.  Let us state some key definitions before proceeding.        

\begin{definition}
A linear code of length n and rank k is a linear subspace C with $dim(C)=k$ of $\mathbb{F}_{q}^{n}$, where $\mathbb{F}_{q}$ is the finite field on q elements. 
\end{definition}	
\begin{definition}
A generator matrix $G$ of a [$n,k,d$] linear code is a $k \times n$ matrix with row space equivalent to $C$.
\end{definition}
\begin{definition}
The distance between two codewords is the number of elements in which they differ.  The distance of a linear code is the minimum distance between two distinct codewords in the code, or equivalently, the minimum weight of any nonzero codewords.
\end{definition}

\paragraph{} The example above is an example of the code $\{000,111\}$.  The codewords in this linear code are 000 and 111.  The number of bits in which these two codewords differ, the distance of the code, is 3.  A code $\{000,001,110,111\}$ does not have the same distance as $\{000,111\}$ because the distance is the \textbf{minimum} distance between two elements in the code.  In the case of the 4-codeword linear code above, that minimum distance is 1.  

\paragraph{} With respect to error-detecting, the amount of errors a code can detect is dependent on the distance of that code.  It is more straightforward to see that a code with distance $d$ can correct $d-1$ errors.  That is because, by the definition of distance, corrupting $d-1$ bits in a valid codeword will necessarily produce an invalid codeword.  Both sender and receiver know that it is an invalid codeword because they know what the bit strings contained in the code are.  That is why in the code $\{000,111\}$, with distance 3, we can detect up to $3-1 = 2$ errors.  

\paragraph{} With respect to error-correcting, the amount of errors a code can correct is also dependent on the distance of that code.  The amount of errors that a code with distance $d$ can correct is $\ceil[\bigcap]{\frac{d}{2}} - 1$.  The reason for this is that once $\frac{d}{2}$ bits are corrupted, there is an ambiguity when it comes to determining what the original, uncorrupted codeword is.  Hence, the code $\{000,111\}$, with distance 3, can correct $\ceil[\big]{\frac{3}{2}}-1 = 2-1 = 1$ error.

\paragraph{} Throughout the rest of the paper we will refer to a linear code of length $n$, dimension $k$, and distance $d$ as an [n,k,d] code or exclude the distance and say $(n,k)$-linear code.  Additionally, when we talk about linear codes, we will talk about binary codes, i.e. linear codes of length n whose codewords are of the form $\{0,1\}^n$. 


\paragraph{} Throughout the rest of the paper we will refer to a linear code of length $n$, dimension $k$, and distance $d$ as an [n,k,d] code or exclude the distance and say $(n,k)$-linear code.  Additionally, when we talk about linear codes, we will talk about binary codes, i.e. linear codes of length n whose codewords are of the form $\{0,1\}^n$. 

\section{Linear codes and cryptosystems}
\paragraph{}
In theory, most public-key cryptosystems are as hard to break as the one-way functions they are typically based on. For example, the security of RSA is based on the fact that factoring large composite numbers is (thought to be) exponentially harder than generating and multiplying large primes. Another commonly seen example of one such system is elliptic curve ElGamal, which is based on the discrete log problem over finite Abelian groups. However, researchers have discovered quantum algorithms that solve both of these problems, and more generally, the Hidden Subgroup Problem restricted to finitely generated Abelian groups in polylogarithmic time.

\paragraph{}
A natural question to ask is whether or not there are public-key cryptosystems that can be both implemented on classical computers but still be safe from quantum attacks. One such difficult problem associated with linear codes is the Nearest Codeword Problem (NCP). Given a generator matrix $G$ for a code $C$, and a (possibly noisy) observation of a codeword $y$, the nearest codeword problem is to find a vector $x$ so that $d(xG, y)$ is minimized (where $d$ represents the Hamming distance). It can be shown that this problem is NP-Hard through a series of reductions through Max-Cut, Not-All-Equal 3-SAT, and finally, 3-SAT.

\paragraph{}
This very naturally suggests a cryptosystem based on the NCP. With a linear code, one can simply encode a message and flip some correctable number of bits to encrypt the message. But then to recover the message, someone needs to solve the NCP. However, the hardness of NCP is reliant on the fact that the code could be any linear code. It's often the case that certain specializations of NP-Hard or NP-Complete problems can be solved quickly. For example, a special case of the Subset Sum problem is solved in polynomial time by cashiers everyday because the set of American coin values is superincreasing. Similarly, there exist linear codes where it is fast to solve the NCP. We discuss examples of such codes later in these notes. 

\paragraph{}
The only remaining obstacle to a public-key cryptosystem based on the hardness of the NCP is to hide or obscure the properties of your chosen code that make it efficient to decode from eavesdroppers. Since we're representing the linear code as a generator matrix, we can apply regular rules of linear algebra to ``hide'' the original generator matrix. Multiplying and adding rows and columns, as well as swapping rows in the generator matrix preserves the row space and thus the code specified by the generator matrix.

\section{The McEliece Cryptosystem}
\paragraph{} The McEliece cryptosystem is an assymetric encryption scheme which derives its security from the hardness of the decoding general linear codes, as described in section 2 of this paper.  The algorithm has garnered more attention after the realization that many common classical public-key cryptosystems will become insecure with the existence of effective quantum computers; the algorithms already exist and the current practicality of implementing the algorithms is the only roadblock.  The cryptosystem leans on three different algorithms: a key generation algorithm, an encryption algorithm, and a decryption algorithm.  Of these three algorithms, only the decryption algorithm is deterministic.  The key generation and encryption algorithms both rely on randomization, meaning there is no strict guarantee that instance of the algorithm will generate different keys, and encrypting the same plaintext with the same keys will not necessarily yield the same ciphertext.  In this section we will explore these three algorithms in detail for a receiver, Alice, a sender, Bob, and a potential evesdropper, Eve.

	\subsection{Key Generation}
	\begin{enumerate}[1)]
		\item Alice selects a binary $(n,k)$-linear code C capable of correcting t errors. This code must possess an efficient decoding algorithm and generates a $k \times n$ generator matrix G for the code C.
		
		\item Alice selects a random $k \times k$ binary non-singular matrix $S$.
		
		\item Alice selects a random $n \times n$ permutation matrix $P$.
		
		\item Alice computes the $k \times n$ matrix ${\hat G} = SGP$
		
		\item Alice's public key is $({\hat G}, t)$; her private key is $(S, G, P)$
	\end{enumerate}	 	

	\paragraph{} The details of the nature of the linear code we are dealing with should be sufficiently explained by previous sections.  However, we have not touched on the idea of a generator matrix.  So recall that an $(n,k)$-linear code C has dimension $k$, meaning that a basis for C consists of $k$ vectors.  The generator matrix has $k$ rows because, by definition, the rows of a generator matrix form the basis for a linear code.  
	\paragraph{} Note that there are $2^{k^2}$ possible matrices that S could be and $2^{n^2}$ possible matrices that P could be.  For that reason, we can safely assume that factoring the public key ${\hat G}$ in order to crack this encryption scheme is not trivial.
	
	\subsection{Encryption}
	\begin{enumerate}[1)]
	\item Bob encodes the message $m$ as a binary string of length k.
	\item Bob computes the vector $c^{\prime} = m{\hat G}$.
	\item Bob generates a random n-bit vector z containing exactly t ones.
	\item Bob computes the ciphertext as $c = c^{\prime} + z$ and sends it to Alice over an insecure channel.  	
	\end{enumerate}	
	\paragraph{} We see a pattern in this encryption function similar to that of RSA and ElGamal.  The message is masked with the public key under an operation that is not trivially reversed, except by the receiver who has access to the secret keys.
	
	\subsection{Decryption}
	\begin{enumerate}[1)]
	\item Alice computes $P^{-1}$
	\item Alice computes ${\hat c} = cP^{-1}$
	\item Alice uses the decoding algorithm for the code C to decode ${\hat c}$ to ${\hat m}$
	\item Alice computes $m = {\hat m}S^{-1}$
	\end{enumerate}

	\subsection{Proof of Decryption}
	\begin{enumerate}
	\item Alice computes ${\hat c} = cP^{-1}$ after receiving $c$
	\item $cP^{-1} = m{\hat G}P^{-1} + zP^{-1}$
	\item Since ${\hat G} = SGP$, $m{\hat G}P^{-1} = mSG$
	\item Then $cP^{-1} = mSG + zP^{-1}$ 
	\item Because $zP^{-1}$ has at most $t$ ones, the distance between $mSG$ and ${\hat c}$ is at most $t$.  The decoding algorithm for C can thus correct the introduced error and decode $mSG$ to produce ${\hat m} = mS$.
	\item Alice then computes $m = {\hat m}S^{-1}$
	
	
	
	\end{enumerate}

\section{Binary Goppa Codes}
\paragraph{}
The above description of the McEliece cryptosystem was entirely agnostic of the linear code used. However, one might guess that certain linear codes might be more amenable to use for concealing secret messages. In particular, a linear code with large distance would be desirable, as this property directly translates into the number of errors that can be corrected per message. The amount of flipped bits in the codeword is a rough indicator of how much one may conceal the message. Also, having a linear code that forces a brute-force attacker to examine a large number of possible codewords is desirable for obvious reasons. 

\paragraph{}
A Binary Goppa code is characterized by a polynomial $p(x) \in GF(2^m)[x]$, where we let $t = deg(p)$, as well as some subset $L$ of $GF(2^m)$ so that for any $l\in L$, $g(l) \not = 0$. Then the actual codewords are every vector $\vec{c}$ so that $\sum_{l\in L} c_i (x-l)^{-1} \equiv 0 (\mod p(x))$. 

\paragraph{}
It can be shown that a general Binary Goppa code has minimum distance $t+1$. By placing additional constraints on $p(x)$, we can increase this lower bound to $2t+1$. The constraint required is that each root of $p(x)$ only has multiplicity one. By increasing the distance of our code, we are now free to increase the number of flipped bits in our noisy codeword.

\end{document}
